import os

configfile: 'config.yaml'

'''Load from config file'''

PICARD = config['PICARD']
GATK = config['GATK']
SAMTOOLS = config['SAMTOOLS']
BCFTOOLS = config['BCFTOOLS']
VCFTOOLS = config['VCFTOOLS']
STAR = config['STAR']

DIR = config['DIR']

INDIVS = []
fn = open('test.txt', 'r')
for line in fn.readlines():
    INDIVS.append(line.rstrip())

FQ_DIR = config['FQ_DIR']
STAR_DIR = config['STAR_DIR']

GENOME = config['GENOME']
GENOME_STAR = config['GENOME_STAR']
GTF = config['GTF']
STAR_GENOME_INDEX = config['STAR_GENOME_INDEX']
VCFFN= config['VCFFN']

SUFFIX = '.star.grch38.Aligned.sortedByCoord.out'

THREADS = config['THREADS']
minDP_arr = config['minDP_arr']


''' Snakemake rules '''
rule all:
    input:
        expand(os.path.join(STAR_DIR, '{indiv}' + '-RG-dedup-hapcal.filtered.genotype.minDP' + '{minDP}' + '.txt'), indiv=INDIVS, minDP = minDP_arr)



rule star_genome_index:
    input:
        genome = GENOME_STAR,
        gtf = GTF
    output:
        index = STAR_GENOME_INDEX
    threads:
        THREADS
    shell:
        '{STAR} --runMode genomeGenerate --runThreadN {threads}  --genomeDir {STAR_GENOME_INDEX} --genomeFastaFiles {input.GENOME_STAR} --sjdbGTFfile {input.GTF} --limitGenomeGenerateRAM 115999096192'



rule star_align:
    input:
        genome_index = STAR_GENOME_INDEX,
        reads1 = os.path.join(FQ_DIR, '{indiv}' + '_r1.fixed.fastq.gz'),
        reads2 = os.path.join(FQ_DIR, '{indiv}' + '_r2.fixed.fastq.gz')
    output:
        bam = os.path.join(STAR_DIR, '{indiv}' + SUFFIX + '.bam')
    params:
        prefix = os.path.join(STAR_DIR, '{indiv}' + '.star.grch38.')
    threads:
        THREADS
    shell:
        '{STAR} --genomeDir {STAR_GENOME_INDEX}  --runThreadN {threads} --readFilesIn {input.reads1} {input.reads2} --readFilesCommand zcat  --varVCFfile {VCFFN}  --outFileNamePrefix {params.prefix} --outSAMtype BAM SortedByCoordinate --outSAMattributes NH HI AS nM NM MD vA vG vW --waspOutputMode SAMtag --bamRemoveDuplicatesType UniqueIdentical --limitBAMsortRAM 35690842466'        


rule index_sam:
    input:
        os.path.join(STAR_DIR, '{indiv}' + SUFFIX + '.bam')
    output:
        os.path.join(STAR_DIR, '{indiv}' + SUFFIX + '.bam.bai')
    shell:
        '{SAMTOOLS} index {input}'


rule keep_autosomal_genome:
    input:
        os.path.join(STAR_DIR, '{indiv}' + SUFFIX + '.bam'),
        os.path.join(STAR_DIR, '{indiv}' + SUFFIX + '.bam.bai')
    output:
        os.path.join(STAR_DIR, '{indiv}' + SUFFIX + '.auto.bam')
    threads:
        THREADS
    shell:
        '{SAMTOOLS} view -@ {threads} -b {input} {{1..22}} > {output}'



RGPL = 'illumina'
RGPU = 'Unknown'

rule add_rg:
    input:
        os.path.join(STAR_DIR, '{indiv}' + SUFFIX + '.auto.bam')
    output:
        os.path.join(STAR_DIR, '{indiv}' + '-RG.bam')
    params:
        tmp = os.path.join(STAR_DIR, 'tmp/indiv'),
        label = '{indiv}',
        grid = '{indiv}',
        rgsm = '{indiv}'
    shell:
        '{PICARD} AddOrReplaceReadGroups I={input}  O={output}  RGID={params.grid} RGLB={params.label} RGPL={RGPL} RGSM={params.rgsm} RGPU={RGPU} TMP_DIR={params.tmp}'

rule mark_dup:
    input:
        os.path.join(STAR_DIR, '{indiv}' + '-RG.bam')
    output:
        bam = os.path.join(STAR_DIR, '{indiv}' + '-RG-dedup.bam'),
        metric = os.path.join(STAR_DIR, '{indiv}' + '.dedup.metrics')
    params:
        tmp = os.path.join(STAR_DIR, 'tmp')
    threads: THREADS
    shell:
        '{PICARD} MarkDuplicates INPUT= {input} OUTPUT= {output.bam} METRICS_FILE= {output.metric} TMP_DIR={params.tmp}'


rule clean_header:
    input:
        os.path.join(STAR_DIR, '{indiv}' + '-RG-dedup.bam')
    output:
        os.path.join(STAR_DIR, '{indiv}' + '-RG-dedup-cleanH.bam')
    shell:
        """
        {SAMTOOLS} view -H {input} | grep -v chr[a-Z] | grep -v random > {output}.temp
        {SAMTOOLS} view {input} >> {output}.temp
        {SAMTOOLS} view -h -b -S {output}.temp > {output}
        rm {output}.temp
        """

rule index_post_removeDup:
    input:
        os.path.join(STAR_DIR, '{indiv}' + '-RG-dedup-cleanH.bam'),
    output:
        os.path.join(STAR_DIR, '{indiv}' + '-RG-dedup-cleanH.bam.bai')
    shell:
        '{SAMTOOLS} index {input}'



'''
Variant calling using GATK
'''

GENOME_DICT = '.'.join(GENOME.split('.')[:-1]) + '.dict'
rule build_genome_dict:
    '''
    Build `.dict` file for reference genome
    '''
    input:
        GENOME
    output:
        GENOME_DICT
    shell:
        '{PICARD} CreateSequenceDictionary R={input} O={output}'

rule GATK_haplotypecaller:
    input:
        bam = os.path.join(BOWTIE_DIR, '{indiv}' + '-RG-dedup-cleanH.bam'),
        bai = os.path.join(BOWTIE_DIR, '{indiv}' + '-RG-dedup-cleanH.bam.bai'),
        genome_dict = GENOME_DICT
    output:
        gvcf_gz = temp(os.path.join(BOWTIE_DIR, '{indiv}-RG-dedup-hapcal.g.vcf.gz'))
    params:
        tmp = os.path.join(BOWTIE_DIR, 'tmp')
    threads: THREADS
    shell:
        '{GATK} --java-options "-XX:ParallelGCThreads={threads}" HaplotypeCaller -R {GENOME} \
            -I {input.bam} -O {output.gvcf_gz} --tmp-dir {params.tmp} --native-pair-hmm-threads {threads} \
            -ERC GVCF'

rule filtergVCF_DP2:
    input:
        os.path.join(BOWTIE_DIR, '{indiv}-RG-dedup-hapcal.g.vcf.gz')
    output:
        temp(os.path.join(BOWTIE_DIR, '{indiv}-RG-dedup-hapcal.filtered.gvcf.recode.vcf'))
    params:
        prefix = os.path.join(BOWTIE_DIR, '{indiv}-RG-dedup-hapcal.filtered.gvcf')
    shell:
        '{VCFTOOLS} --gzvcf {input} --min-meanDP 2 --recode --recode-INFO-all --out {params.prefix}'



'''
Process VCF file
'''

rule gvcf2vcf:
    input:
        os.path.join(BOWTIE_DIR, '{indiv}-RG-dedup-hapcal.filtered.gvcf.recode.vcf')
    output:
        temp(os.path.join(BOWTIE_DIR, '{indiv}-RG-dedup-hapcal.filtered.recode.vcf'))
    shell:
        """
        {BCFTOOLS} convert --gvcf2vcf {input} -f {GENOME} > {output}
        """


oneK_variants_locations='/work-zfs/abattle4/heyuan/Variant_calling/benchmarking/datasets/GBR/Genotype/1k_genome.variants.locations.txt'
rule filterVCF_1k_variants:
    input:
        os.path.join(BOWTIE_DIR, '{indiv}-RG-dedup-hapcal.filtered.recode.vcf')
    output:
        os.path.join(BOWTIE_DIR, 'VCF_files', '{indiv}-RG-dedup-hapcal.filtered.variants.recode.vcf'),
        os.path.join(BOWTIE_DIR, 'VCF_files', '{indiv}-RG-dedup-hapcal.filtered.variants.recode.INFO.txt')
    params:
        prefix = os.path.join(BOWTIE_DIR, '{indiv}-RG-dedup-hapcal.filtered.variants')
    shell:
        """
        {VCFTOOLS} --vcf {input} --out {params.prefix} --positions {oneK_variants_locations} --recode
        {BCFTOOLS} query -f '%CHROM\t%POS\t[%DP\t%PL\t%GQ]\n' {params.prefix}.recode.vcf > {params.prefix}.recode.INFO.txt
        cp os.path.join(BOWTIE_DIR, '{params.prefix}.recode.vcf') os.path.join(BOWTIE_DIR, 'save_VCF_files/')
        """


rule filterVCF_minDP:
    input:
        os.path.join(BOWTIE_DIR, 'VCF_files', '{indiv}' + '-RG-dedup-hapcal.filtered.variants.recode.vcf')
    output:
        temp(os.path.join(BOWTIE_DIR, 'VCF_files', '{indiv}' + '-RG-dedup-hapcal.filtered.variants.minDP' + '{minDP}' + '.recode.vcf'))
    params:
        minimumdp = '{minDP}',
        prefix = os.path.join(BOWTIE_DIR, '{indiv}' + '-RG-dedup-hapcal.filtered.variants.minDP' + '{minDP}')
    shell:
        """
        {VCFTOOLS} --vcf {input} --min-meanDP {params.minimumdp} --recode --recode-INFO-all --out {params.prefix}
        """


'''
Call genotypes
'''

rule call_genotype:
    input:
        os.path.join(BOWTIE_DIR, 'VCF_files', '{indiv}-RG-dedup-hapcal.filtered.variants.minDP' + '{minDP}' + '.recode.vcf')
    output:
        os.path.join(BOWTIE_DIR, 'Called_GT', '{indiv}-RG-dedup-hapcal.filtered.genotype.minDP' + '{minDP}' + '.txt')
    conda:
        "envs/env_py37.yml"
    shell:
        'vcf-to-tab < {input} > {output}'


